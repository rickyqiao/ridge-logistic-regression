{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_train=pd.read_csv('D:/hkust_s2/5054/mid/card_train.csv', index_col=0)\n",
    "card_test=pd.read_csv('D:/hkust_s2/5054/mid/card_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(card_train[card_train.columns.tolist()[1:-1]], card_train[card_train.columns.tolist()[-1]])\n",
    "predict=clf.predict_proba(card_test.iloc[:,1:-1])\n",
    "predict_1_prob=[i[1] for i in predict]\n",
    "predict_1_0=[1 if i>=0.5  else 0 for i in predict_1_prob ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the overall error is 0.0008273894436519047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('the overall error is '+str(1-accuracy_score(card_test['Class'], predict_1_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "\n",
    "init_error=1\n",
    "for ii in np.arange(0,1,0.02):\n",
    "    error_tmp=find_threshold(ii)\n",
    "    if error_tmp<init_error:\n",
    "        init_error=error_tmp\n",
    "        threshold_final=ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69977,    23],\n",
       "       [   26,    74]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "###01\n",
    "##0\n",
    "##1\n",
    "predict_tmp=[1 if i>=0.16  else 0 for i in predict_1_prob ]\n",
    "C_matrix=confusion_matrix(card_test['Class'], predict_tmp)\n",
    "C_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085106382978723"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####sensitivity\n",
    "C_matrix[1][1]/(C_matrix[1][1]+C_matrix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996571722423793"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####specificity\n",
    "C_matrix[0][0]/(C_matrix[0][0]+C_matrix[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when threshold=0.5, the overall error of LR is 0.0008273894436519047\n",
      "the perfect threshold is 0.16\n",
      " the sensitivity of LR with threshod 0.16 is 0.7628865979381443\n",
      " the specificity of LR with threshod 0.16 is 0.9996285873462566\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = LogisticRegression(random_state=0).fit(card_train[card_train.columns.tolist()[1:-1]], card_train[card_train.columns.tolist()[-1]])\n",
    "predict=clf.predict_proba(card_test.iloc[:,1:-1])\n",
    "predict_1_prob=[i[1] for i in predict]\n",
    "predict_1_0=[1 if i>=0.5  else 0 for i in predict_1_prob ]\n",
    "print('when threshold=0.5, the overall error of LR is '+str(1-accuracy_score(card_test['Class'], predict_1_0)))\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "init_error=1\n",
    "for ii in np.arange(0,1,0.02):\n",
    "    error_tmp=find_threshold(ii)\n",
    "    if error_tmp<init_error:\n",
    "        init_error=error_tmp\n",
    "        threshold_final=ii\n",
    "print('the perfect threshold is '+str(threshold_final))\n",
    "predict_tmp=[1 if i>=threshold_final  else 0 for i in predict_1_prob ]\n",
    "C_matrix=confusion_matrix(card_test['Class'], predict_tmp)\n",
    "####sensitivity\n",
    "print(' the sensitivity of LR with threshod '+str(threshold_final) +' is '+str(C_matrix[1][1]/(C_matrix[1][1]+C_matrix[0][1])))\n",
    "####specificity\n",
    "print(' the specificity of LR with threshod '+str(threshold_final) +' is '+str(C_matrix[0][0]/(C_matrix[0][0]+C_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when threshold=0.5, the overall error of LDA is 0.0006134094151212244\n",
      "the perfect threshold is 0.02\n",
      " the sensitivity of LDA with threshod 0.02 is 0.8085106382978723\n",
      " the specificity of LDA with threshod 0.02 is 0.9996571722423793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis().fit(card_train[card_train.columns.tolist()[1:-1]], card_train[card_train.columns.tolist()[-1]])\n",
    "predict=clf.predict_proba(card_test.iloc[:,1:-1])\n",
    "predict_1_prob=[i[1] for i in predict]\n",
    "predict_1_0=[1 if i>=0.5  else 0 for i in predict_1_prob ]\n",
    "print('when threshold=0.5, the overall error of LDA is '+str(1-accuracy_score(card_test['Class'], predict_1_0)))\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "init_error=1\n",
    "for ii in np.arange(0,1,0.02):\n",
    "    error_tmp=find_threshold(ii)\n",
    "    if error_tmp<init_error:\n",
    "        init_error=error_tmp\n",
    "        threshold_final=ii\n",
    "print('the perfect threshold is '+str(threshold_final))\n",
    "predict_tmp=[1 if i>=threshold_final  else 0 for i in predict_1_prob ]\n",
    "C_matrix=confusion_matrix(card_test['Class'], predict_tmp)\n",
    "####sensitivity\n",
    "print(' the sensitivity of LDA with threshod '+str(threshold_final) +' is '+str(C_matrix[1][1]/(C_matrix[1][1]+C_matrix[0][1])))\n",
    "####specificity\n",
    "print(' the specificity of LDA with threshod '+str(threshold_final) +' is '+str(C_matrix[0][0]/(C_matrix[0][0]+C_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when thershold=0.5, the overall error of QDA is 0.02286733238231098\n",
      "the perfect threshold is 0.98\n",
      " the sensitivity of QDA with threshod 0.98 is 0.06976744186046512\n",
      " the specificity of QDA with threshod 0.98 is 0.9997677659080353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf = QuadraticDiscriminantAnalysis().fit(card_train[card_train.columns.tolist()[1:-1]], card_train[card_train.columns.tolist()[-1]])\n",
    "predict=clf.predict_proba(card_test.iloc[:,1:-1])\n",
    "predict_1_prob=[i[1] for i in predict]\n",
    "predict_1_0=[1 if i>=0.5  else 0 for i in predict_1_prob ]\n",
    "print('when thershold=0.5, the overall error of QDA is '+str(1-accuracy_score(card_test['Class'], predict_1_0)))\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "init_error=1\n",
    "for ii in np.arange(0,1,0.02):\n",
    "    error_tmp=find_threshold(ii)\n",
    "    if error_tmp<init_error:\n",
    "        init_error=error_tmp\n",
    "        threshold_final=ii\n",
    "print('the perfect threshold is '+str(threshold_final))\n",
    "predict_tmp=[1 if i>=threshold_final  else 0 for i in predict_1_prob ]\n",
    "C_matrix=confusion_matrix(card_test['Class'], predict_tmp)\n",
    "####sensitivity\n",
    "print(' the sensitivity of QDA with threshod '+str(threshold_final) +' is '+str(C_matrix[1][1]/(C_matrix[1][1]+C_matrix[0][1])))\n",
    "####specificity\n",
    "print(' the specificity of QDA with threshod '+str(threshold_final) +' is '+str(C_matrix[0][0]/(C_matrix[0][0]+C_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best threshold of LR in 5CV is 0.2\n",
      " the sensitivity of LR with threshod 0.2 is 0.7717391304347826\n",
      " the specificity of LR with threshod 0.2 is 0.9995857616272426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "#kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate the splits and summarize the distributions\n",
    "X=card_train[card_train.columns.tolist()[1:-1]]\n",
    "Y=card_train[card_train.columns.tolist()[-1]]\n",
    "init_error=1\n",
    "error_list=[]\n",
    "for threshold in np.arange(0,1,0.1):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    error_tmp=0\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select rows\n",
    "        train_X, test_X = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        train_y, test_y = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "        clf = LogisticRegression(random_state=0).fit(train_X, train_y)\n",
    "        predict=clf.predict_proba(card_test.iloc[:,1:-1])\n",
    "        predict_1_prob=[i[1] for i in predict]\n",
    "        predict_1_0=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "        error_tmp+=1-accuracy_score(card_test['Class'], predict_1_0)\n",
    "    error_tmp=error_tmp/5\n",
    "    error_list.append(error_tmp)\n",
    "    if error_tmp<init_error:\n",
    "        init_error=error_tmp\n",
    "        threshold_final=threshold\n",
    "print('the best threshold of LR in 5CV is '+str(threshold_final))\n",
    "predict_tmp=[1 if i>=threshold_final  else 0 for i in predict_1_prob ]\n",
    "C_matrix=confusion_matrix(card_test['Class'], predict_tmp)\n",
    "####sensitivity\n",
    "print(' the sensitivity of LR with threshod '+str(threshold_final) +' is '+str(C_matrix[1][1]/(C_matrix[1][1]+C_matrix[0][1])))\n",
    "####specificity\n",
    "print(' the specificity of LR with threshod '+str(threshold_final) +' is '+str(C_matrix[0][0]/(C_matrix[0][0]+C_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(0,1,0.1),error_list)\n",
    "plt.title(\"LR loss\")\n",
    "plt.xlim(0.1,1)\n",
    "plt.ylim(0,0.002)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the overall error when threshold is 0.5 is 0.0008273894436519047\n",
      "the overall error when threshold is 0.16 get in search is 0.0006990014265335631\n",
      "the overall error when threshold is 0.2 get in 5-fold is 0.0006990014265335631\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(card_train[card_train.columns.tolist()[1:-1]], card_train[card_train.columns.tolist()[-1]])\n",
    "predict=clf.predict_proba(card_test.iloc[:,1:-1])\n",
    "predict_1_prob=[i[1] for i in predict]\n",
    "predict_1_0=[1 if i>=0.5  else 0 for i in predict_1_prob ]\n",
    "print('the overall error when threshold is 0.5 is '+str(1-accuracy_score(card_test['Class'], predict_1_0)))\n",
    "predict_1_0=[1 if i>=0.16  else 0 for i in predict_1_prob ]\n",
    "print('the overall error when threshold is 0.16 get in search is '+str(1-accuracy_score(card_test['Class'], predict_1_0)))\n",
    "predict_1_0=[1 if i>=0.2  else 0 for i in predict_1_prob ]\n",
    "print('the overall error when threshold is 0.2 get in 5-fold is '+str(1-accuracy_score(card_test['Class'], predict_1_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best threshold of LDA in 5CV is 0.05\n",
      " the sensitivity of LDA with threshod 0.05 is 0.8085106382978723\n",
      " the specificity of LDA with threshod 0.05 is 0.9996571722423793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "#kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate the splits and summarize the distributions\n",
    "X=card_train[card_train.columns.tolist()[1:-1]]\n",
    "Y=card_train[card_train.columns.tolist()[-1]]\n",
    "init_error=1\n",
    "error_list=[]\n",
    "for threshold in np.arange(0,1,0.05):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    error_tmp=0\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select rows\n",
    "        train_X, test_X = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        train_y, test_y = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "        clf = LinearDiscriminantAnalysis().fit(train_X, train_y)\n",
    "        predict=clf.predict_proba(card_test.iloc[:,1:-1])\n",
    "        predict_1_prob=[i[1] for i in predict]\n",
    "        predict_1_0=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "        error_tmp+=1-accuracy_score(card_test['Class'], predict_1_0)\n",
    "    error_tmp=error_tmp/5\n",
    "    error_list.append(error_tmp)\n",
    "    if error_tmp<init_error:\n",
    "        init_error=error_tmp\n",
    "        threshold_final=threshold\n",
    "print('the best threshold of LDA in 5CV is '+str(threshold_final))\n",
    "predict_tmp=[1 if i>=threshold_final  else 0 for i in predict_1_prob ]\n",
    "C_matrix=confusion_matrix(card_test['Class'], predict_tmp)\n",
    "####sensitivity\n",
    "print(' the sensitivity of LDA with threshod '+str(threshold_final) +' is '+str(C_matrix[1][1]/(C_matrix[1][1]+C_matrix[0][1])))\n",
    "####specificity\n",
    "print(' the specificity of LDA with threshod '+str(threshold_final) +' is '+str(C_matrix[0][0]/(C_matrix[0][0]+C_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"D:/hkust_s2/5054/mid/Duke_train.txt\",\"r\")\n",
    "Duke_train = f2.readlines()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duke_train=[ll.split(',') for ll in Duke_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duke_train_X=[]\n",
    "for line in Duke_train:\n",
    "    tmp=[]\n",
    "    for i in range(1,len(line)):\n",
    "        tmp.append(float(line[i].replace('\\n','')))\n",
    "    Duke_train_X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duke_train_Y=[float(ll[0]) for ll in Duke_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"D:/hkust_s2/5054/mid/Duke_test.txt\",\"r\")\n",
    "Duke_test = f2.readlines()\n",
    "f2.close()\n",
    "Duke_test=[ll.split(',') for ll in Duke_test]\n",
    "Duke_test_X=[]\n",
    "for line in Duke_test:\n",
    "    tmp=[]\n",
    "    for i in range(1,len(line)):\n",
    "        tmp.append(float(line[i].replace('\\n','')))\n",
    "    Duke_test_X.append(tmp)\n",
    "Duke_test_Y=[float(ll[0]) for ll in Duke_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=0).fit(Duke_train_X, Duke_train_Y)\n",
    "LDA = LinearDiscriminantAnalysis().fit(Duke_train_X, Duke_train_Y)\n",
    "QDA = QuadraticDiscriminantAnalysis().fit(pd.DataFrame(Duke_train_X), pd.DataFrame(Duke_train_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(w,x,y,lam):\n",
    "    loss=0\n",
    "    for i in range(0,len(x)):\n",
    "        #print(i)\n",
    "        try:\n",
    "            loss+=y[i]*np.dot(w,x[i])-math.log(1+math.exp(np.dot(w,x[i])))\n",
    "        except OverflowError:\n",
    "            loss+=(y[i]-1)*np.dot(w,x[i])\n",
    "        #print(loss)\n",
    "    loss-=lam*sum([p**2 for p in w[0]])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_d1_mat(w,x,y,lam):\n",
    "    b=np.array([y]).T-sigmoid(np.dot(x,w))\n",
    "    #print(b.shape)\n",
    "    grad=np.dot(x.T,b)-lam*w\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_d2_mat(w,x,y,lam):\n",
    "    ###build a diagonal matrix first\n",
    "    diag_w=np.diag(np.ravel([np.exp(np.dot(x_tmp,w)/(1+math.exp(np.dot(x_tmp,w)))) for x_tmp in x]))\n",
    "    hessian = (-1 * np.dot(np.dot(x.T , diag_w) , x))-(lam*np.identity(len(x[0])))\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return  1/(1 + np.exp(-x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_LR(Duke_train_X,Duke_train_Y,lam):\n",
    "    w0=np.array([0 for i in range(len(Duke_train_X[0]))])\n",
    "    for iteration in range(251):\n",
    "        if iteration==0:\n",
    "            w_update=w0\n",
    "        loss_tmp=loss_func(w_update,np.array(Duke_train_X),np.array(Duke_train_Y),lam)\n",
    "        w_update2=w_update-\\\n",
    "        loss_func_d1(w_update,np.array(Duke_train_X),np.array(Duke_train_Y),lam)/loss_func_d2(w_update,np.array(Duke_train_X)\n",
    "                                                                                              ,np.array(Duke_train_Y),lam)\n",
    "        w_update=w_update2\n",
    "        #ttt=[sigmoid(np.dot(w_update,x_tmp)) for x_tmp in np.array(Duke_train_X)]\n",
    "        #predict_tmp=[1 if i>=0.5  else 0 for i in ttt ]\n",
    "    return loss_func(w_update,np.array(Duke_train_X),np.array(Duke_train_Y),lam),w_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_LR_mat(Duke_train_X,Duke_train_Y,lam):\n",
    "    w0=np.array([0 for i in range(len(Duke_train_X[0]))])\n",
    "    for iteration in range(15):\n",
    "        #print(iteration)\n",
    "        if iteration==0:\n",
    "            w_update=np.array([w0]).T\n",
    "        loss_tmp=loss_func(w_update.T,np.array(Duke_train_X),np.array(Duke_train_Y),lam)\n",
    "        grad=loss_func_d1_mat(w_update,np.array(Duke_train_X),np.array(Duke_train_Y),1)\n",
    "        hessian=loss_func_d2_mat(w_update,np.array(Duke_train_X),np.array(Duke_train_Y),1)\n",
    "        hessian_inv=np.linalg.inv(hessian)\n",
    "        w_update=w_update-np.dot(hessian_inv,grad)\n",
    "        #ttt=[sigmoid(np.dot(w_update,x_tmp)) for x_tmp in np.array(Duke_train_X)]\n",
    "        #predict_tmp=[1 if i>=0.5  else 0 for i in ttt ]\n",
    "    return loss_func(w_update.T,np.array(Duke_train_X),np.array(Duke_train_Y),lam),w_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-9.6490801]), array([[-0.00129553],\n",
       "        [ 0.00253505],\n",
       "        [-0.00256999],\n",
       "        ...,\n",
       "        [ 0.00358974],\n",
       "        [-0.00053833],\n",
       "        [ 0.00299863]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train_ridge_LR_mat(X,Y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      " the lambda is: 0.5 , and the loss is : -14.770582539098555\n",
      "1\n",
      " the lambda is: 1 , and the loss is : -14.895968764686483\n",
      "2\n",
      " the lambda is: 2 , and the loss is : -15.146741215862345\n",
      "10\n",
      " the lambda is: 10 , and the loss is : -17.15292082526925\n",
      "50\n",
      " the lambda is: 50 , and the loss is : -27.183818872303743\n",
      "100\n",
      " the lambda is: 100 , and the loss is : -39.72244143109687\n",
      "the max loss in 5CV is -14.770582539098555\n",
      "the best lambda is 0.5\n"
     ]
    }
   ],
   "source": [
    "####mat type\n",
    "from sklearn.model_selection import KFold\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "#kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate the splits and summarize the distributions\n",
    "X=np.array(Duke_train_X)\n",
    "Y=np.array(Duke_train_Y)\n",
    "init_error=-999999\n",
    "item_time=0\n",
    "for lam in [0.5,1,2,10,50,100]:\n",
    "    print(lam)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    loss_tmp=0\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select rows\n",
    "        item_time+=1\n",
    "        #print(item_time)\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = Y[train_ix], Y[test_ix]\n",
    "        loss_train,weight = train_ridge_LR_mat(train_X, train_y,lam)\n",
    "        #predict=[sigmoid(np.dot(weight,x_tmp)) for x_tmp in np.array(test_X)]\n",
    "        loss_test=loss_func(weight.T,test_X,test_y,lam)\n",
    "        loss_tmp+=loss_test[0]\n",
    "    loss_tmp=loss_tmp/5\n",
    "    if loss_tmp>init_error:\n",
    "        init_error=loss_tmp\n",
    "        best_lam=lam\n",
    "    print(' the lambda is: '+str(lam)+' , and the loss is : '+str(loss_tmp))\n",
    "print('the max loss in 5CV is '+str(init_error))\n",
    "print('the best lambda is '+str(best_lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      " the lambda is: 0.5 , and the loss is : -14.770582539098555 and the accuracy is 0.7692307692307693\n",
      "1\n",
      " the lambda is: 1 , and the loss is : -14.895968764686483 and the accuracy is 0.7692307692307693\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-45595772ff61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ridge_LR_mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m#predict=[sigmoid(np.dot(weight.T,x_tmp)[0]) for x_tmp in np.array(test_X)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#predict_1_0=[1 if i>=0.5  else 0 for i in predict ]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-65b6eb6fdcb1>\u001b[0m in \u001b[0;36mtrain_ridge_LR_mat\u001b[1;34m(Duke_train_X, Duke_train_Y, lam)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_func_d1_mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_update\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDuke_train_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDuke_train_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mhessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_func_d2_mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_update\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDuke_train_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDuke_train_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mhessian_inv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mw_update\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw_update\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhessian_inv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#ttt=[sigmoid(np.dot(w_update,x_tmp)) for x_tmp in np.array(Duke_train_X)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####mat type\n",
    "from sklearn.model_selection import KFold\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "#kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate the splits and summarize the distributions\n",
    "X=np.array(Duke_train_X)\n",
    "Y=np.array(Duke_train_Y)\n",
    "init_error=-999999\n",
    "item_time=0\n",
    "for lam in [0.5,1,10,100]:\n",
    "    print(lam)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    loss_tmp=0\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select rows\n",
    "        item_time+=1\n",
    "        #print(item_time)\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = Y[train_ix], Y[test_ix]\n",
    "        loss_train,weight = train_ridge_LR_mat(train_X, train_y,lam)\n",
    "        #predict=[sigmoid(np.dot(weight.T,x_tmp)[0]) for x_tmp in np.array(test_X)]\n",
    "        #predict_1_0=[1 if i>=0.5  else 0 for i in predict ]\n",
    "        #accuracy_score(test_y, predict)\n",
    "        loss_test=loss_func(weight.T,test_X,test_y,lam)\n",
    "        loss_tmp+=loss_test[0]\n",
    "    loss_tmp=loss_tmp/5\n",
    "    if loss_tmp>init_error:\n",
    "        init_error=loss_tmp\n",
    "        best_lam=lam\n",
    "        predict=[sigmoid(np.dot(weight.T,x_tmp)[0]) for x_tmp in np.array(test_X)]\n",
    "        predict_1_0=[1 if i>=0.5  else 0 for i in predict ]\n",
    "    print(' the lambda is: '+str(lam)+' , and the loss is : '+str(loss_tmp)+' and the accuracy is '+str(accuracy_score(test_y, predict_1_0)))\n",
    "print('the max loss in 5CV is '+str(init_error))\n",
    "print('the best lambda is '+str(best_lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.541307335516482"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(weight.T,np.array(test_X)[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "####we choose lambda  as 0.5\n",
    "loss,weight=train_ridge_LR_mat(Duke_train_X,Duke_train_Y,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=[sigmoid(np.dot(weight,x_tmp)) for x_tmp in np.array(Duke_test_X)]\n",
    "predict_1_0=[1 if i>=0.5  else 0 for i in predict ]\n",
    "print('the overall error is '+str(1-accuracy_score(Duke_test_Y, predict_1_0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_k(X,Y,target):\n",
    "    index=[i for i in range(len(Y)) if Y[i] == target]\n",
    "    return np.mean(X[index], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_k(Y,target):\n",
    "    return len([i for i in range(len(Y)) if Y[i] == target])/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_matrix(X,Y,target_list,lam):\n",
    "    init_mat=np.zeros([len(X[0]),len(X[0])])\n",
    "    for target in target_list:\n",
    "        uk=u_k(X,Y,target)\n",
    "        index_list=[i for i in range(len(Y)) if Y[i] == target]\n",
    "        cov_matrix=np.cov(X[index_list].T)\n",
    "        init_mat+=cov_matrix\n",
    "    init_mat=init_mat/(len(X)-len(target_list))\n",
    "    identity_mat=np.eye(len(X[0]))\n",
    "    init_mat+=lam*identity_mat\n",
    "    return init_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirac(x,r_mat_inv,X,Y,target):\n",
    "    uk=u_k(X,Y,target)\n",
    "    #uk_inv=np.linalg.inv(uk)\n",
    "    #r_matrix=ridge_matrix(X,Y,[0,1],lam)\n",
    "    #r_mat_inv=np.linalg.inv(r_matrix)\n",
    "    pik=pi_k(Y,target)\n",
    "    #result=np.dot(np.dot(uk.T,r_mat_inv),x)-0.5*np.dot(np.dot(uk.T,r_mat_inv),uk)+math.log(pik)\n",
    "    result=np.dot(np.dot(x.T,r_mat_inv),uk)-0.5*np.dot(np.dot(uk.T,r_mat_inv),uk)+math.log(pik)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(x,r_mat_inv,train_X,train_Y):\n",
    "    pred_1=dirac(x,r_mat_inv,train_X,train_Y,1)\n",
    "    pred_0=dirac(x,r_mat_inv,train_X,train_Y,0)\n",
    "    if pred_1>pred_0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " the lambda is: 0 , and the error_rate is : 0.5505494505494506\n",
      "0.1\n",
      " the lambda is: 0.1 , and the error_rate is : 0.04615384615384614\n",
      "0.5\n",
      " the lambda is: 0.5 , and the error_rate is : 0.04615384615384614\n",
      "1\n",
      " the lambda is: 1 , and the error_rate is : 0.04615384615384614\n",
      "2\n",
      " the lambda is: 2 , and the error_rate is : 0.04615384615384614\n",
      "10\n",
      " the lambda is: 10 , and the error_rate is : 0.07692307692307691\n",
      "50\n",
      " the lambda is: 50 , and the error_rate is : 0.16813186813186812\n",
      "100\n",
      " the lambda is: 100 , and the error_rate is : 0.2593406593406593\n",
      "the min error_rate in 5CV is 0.04615384615384614\n",
      "the best lambda is 0.1\n"
     ]
    }
   ],
   "source": [
    "###LDA K-fold\n",
    "def find_threshold(threshold):\n",
    "    predict_tmp=[1 if i>=threshold  else 0 for i in predict_1_prob ]\n",
    "    return 1-accuracy_score(card_test['Class'], predict_tmp)\n",
    "#kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate the splits and summarize the distributions\n",
    "X=np.array(Duke_train_X)\n",
    "Y=np.array(Duke_train_Y)\n",
    "init_error=999999\n",
    "for lam in [0,0.1,0.5,1,2,10,50,100]:\n",
    "    print(lam)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    error_rate=0\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        # select rows\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = Y[train_ix], Y[test_ix]\n",
    "        r_matrix=ridge_matrix(train_X,train_y,[0,1],lam)\n",
    "        r_mat_inv=np.linalg.inv(r_matrix)\n",
    "        predict=[judge(x_tmp,r_mat_inv,train_X,train_y) for x_tmp in test_X ]\n",
    "        error_rate+=1-accuracy_score(test_y, predict)\n",
    "    error_rate=error_rate/5\n",
    "    if error_rate<init_error:\n",
    "        init_error=error_rate\n",
    "        best_lam=lam\n",
    "    print(' the lambda is: '+str(lam)+' , and the error_rate is : '+str(error_rate))\n",
    "print('the min error_rate in 5CV is '+str(init_error))\n",
    "print('the best lambda is '+str(best_lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###so we choose lambda as 1\n",
    "r_matrix=ridge_matrix(np.array(Duke_train_X),np.array(Duke_train_Y),[0,1],1)\n",
    "r_mat_inv=np.linalg.inv(r_matrix)\n",
    "predict=[judge(x_tmp,r_mat_inv,train_X,train_y) for x_tmp in np.array(Duke_test_X) ]\n",
    "print('the overall error is '+str(1-accuracy_score(Duke_test_Y, predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the overall error is 0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "predict=[judge(x_tmp,r_mat_inv,np.array(Duke_train_X),np.array(Duke_train_Y)) for x_tmp in np.array(Duke_test_X) ]\n",
    "print('the overall error is '+str(1-accuracy_score(Duke_test_Y, predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
